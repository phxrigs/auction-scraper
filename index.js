const puppeteer = require('puppeteer');
const { google } = require('googleapis');

// üîê Secure credentials via environment
const keys = JSON.parse(process.env.GOOGLE_CREDENTIALS);
keys.private_key = keys.private_key.replace(/\\n/g, '\n');

(async () => {
  const auth = new google.auth.JWT(
    keys.client_email,
    null,
    keys.private_key,
    ['https://www.googleapis.com/auth/spreadsheets']
  );
  await auth.authorize();
  const sheets = google.sheets({ version: 'v4', auth });

  const spreadsheetId = '1CypDOy2PseT9FPz9cyz1JdFhsUmyfnrMGKSmJ2V0fe0';
  const sheetName = 'InHunt';

  const rowCount = (
    await sheets.spreadsheets.values.get({
      spreadsheetId,
      range: `${sheetName}!A2:A`,
    })
  ).data.values?.length || 0;
  console.log(`üìò Found ${rowCount} rows`);

  const urlRes = await sheets.spreadsheets.values.get({
    spreadsheetId,
    range: `${sheetName}!T2:T${rowCount + 1}`,
  });
  const urls = urlRes.data.values || [];

  const browser = await puppeteer.launch({
    headless: true,
    args: ['--no-sandbox', '--disable-setuid-sandbox'],
  });

  const BATCH_SIZE = 5;
  const updates = [];

  for (let i = 0; i < urls.length; i += BATCH_SIZE) {
    const batch = urls.slice(i, i + BATCH_SIZE);

    const results = await Promise.all(
      batch.map(async (row, index) => {
        const rowIndex = i + index + 2;
        const url = row[0];
        if (!url || url.trim() === '') {
          console.log(`‚è≠Ô∏è Row ${rowIndex}: empty URL`);
          return null;
        }

        const page = await browser.newPage();
        const start = Date.now();

        try {
          console.log(`üåê Row ${rowIndex}: visiting ${url}`);
          await page.goto(url, { waitUntil: 'domcontentloaded' });

          const bidSelector = '.item-detail-current-bid span[data-currency]';
          await page.waitForSelector(bidSelector, { timeout: 2000 });
          const bid = await page.$eval(bidSelector, el => el.textContent.trim());

          // üñºÔ∏è Try primary selector first
          let imageUrls = await page.$$eval(
            '.fotorama__stage__shaft img.fotorama__img',
            imgs => imgs.map(img => img.src)
          );

          // üñºÔ∏è Fallback if primary fails
          if (imageUrls.length === 0) {
            console.log(`üîÅ Row ${rowIndex}: trying fallback selector`);
            imageUrls = await page.$$eval(
              '.product-image img',
              imgs => imgs.map(img => img.src)
            );
          }

          // üì∑ Log results
          if (imageUrls.length === 0) {
            console.log(`üö´ Row ${rowIndex}: no images found`);
          } else {
            console.log(`üñºÔ∏è Row ${rowIndex}: first image ‚Üí ${imageUrls[0]}`);
          }

          const imageFormula = imageUrls[0]
            ? `=IMAGE("${imageUrls[0]}", 4, 60, 60)`
            : '';

          const duration = Date.now() - start;
          console.log(`‚úÖ Row ${rowIndex}: üí∞ ${bid}, üñºÔ∏è ${imageUrls[0] ? '‚úî' : '‚úò'} (${duration}ms)`);

          return [
            { range: `${sheetName}!V${rowIndex}`, values: [[bid]] },
            { range: `${sheetName}!AC${rowIndex}`, values: [[imageFormula]] },
          ];
        } catch (err) {
          console.warn(`‚ö†Ô∏è Row ${rowIndex}: scrape error ‚Äî ${err.message}`);
          return null;
        } finally {
          await page.close();
        }
      })
    );

    results.flat().forEach(update => {
      if (update) updates.push(update);
    });
  }

  await browser.close();

  if (updates.length > 0) {
    await sheets.spreadsheets.values.batchUpdate({
      spreadsheetId,
      requestBody: {
        valueInputOption: 'RAW',
        data: updates,
      },
    });
    console.log(`üìä ${updates.length} updates written to sheet`);
  } else {
    console.log('‚ÑπÔ∏è No updates to apply');
  }
})();
